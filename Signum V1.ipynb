{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as torch_onnx\n",
    "import onnx\n",
    "import cv2\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving to GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/arth'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mASL-Translator\u001b[m\u001b[m                  \u001b[34mPostman\u001b[m\u001b[m\n",
      "\u001b[30m\u001b[43mAdlm\u001b[m\u001b[m                            \u001b[34mPublic\u001b[m\u001b[m\n",
      "\u001b[34mApplications\u001b[m\u001b[m                    \u001b[34mPycharmProjects\u001b[m\u001b[m\n",
      "\u001b[34mCreative Cloud Files\u001b[m\u001b[m            \u001b[34mShit\u001b[m\u001b[m\n",
      "\u001b[34mDesktop\u001b[m\u001b[m                         \u001b[34mSpring 2019\u001b[m\u001b[m\n",
      "\u001b[34mDocuments\u001b[m\u001b[m                       Untitled.ipynb\n",
      "\u001b[34mDownloads\u001b[m\u001b[m                       Untitled1.ipynb\n",
      "Essay 1 Outline.docx            \u001b[34mVirtual Machines.localized\u001b[m\u001b[m\n",
      "\u001b[34mLibrary\u001b[m\u001b[m                         \u001b[34mcode\u001b[m\u001b[m\n",
      "\u001b[34mMovies\u001b[m\u001b[m                          \u001b[34mcs61b-software\u001b[m\u001b[m\n",
      "\u001b[34mMusic\u001b[m\u001b[m                           \u001b[34mdev\u001b[m\u001b[m\n",
      "\u001b[34mNew\u001b[m\u001b[m                             \u001b[34menv\u001b[m\u001b[m\n",
      "Normal Processing.ipynb         \u001b[34mopt\u001b[m\u001b[m\n",
      "Parallel Processing_Final.ipynb \u001b[34mrepo\u001b[m\u001b[m\n",
      "\u001b[34mPictures\u001b[m\u001b[m                        w210-fall19-deepfake.pem\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"sign_mnist_train.csv\")\n",
    "length = data_frame.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      3     107     118     127     134     139     143     146     150   \n",
       "1      6     155     157     156     156     156     157     156     158   \n",
       "2      2     187     188     188     187     187     186     187     188   \n",
       "3      2     211     211     212     212     211     210     211     210   \n",
       "4     13     164     167     170     172     176     179     180     184   \n",
       "\n",
       "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0     153  ...       207       207       207       207       206       206   \n",
       "1     158  ...        69       149       128        87        94       163   \n",
       "2     187  ...       202       201       200       199       198       199   \n",
       "3     210  ...       235       234       233       231       230       226   \n",
       "4     185  ...        92       105       105       108       133       163   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       206       204       203       202  \n",
       "1       175       103       135       149  \n",
       "2       198       195       194       195  \n",
       "3       225       222       229       163  \n",
       "4       157       163       164       179  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentations\n",
    "\n",
    "transform = transforms.Compose([transforms.RandomResizedCrop(28, scale=(0.8, 1.2)), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Âµs, sys: 0 ns, total: 4 Âµs\n",
      "Wall time: 6.91 Âµs\n"
     ]
    }
   ],
   "source": [
    "# Implementing the custom dataset and dataloader\n",
    "\n",
    "class ImageSet(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.data_frame = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Fetching items at given idx through Dataloader\"\"\"\n",
    "        \n",
    "        label = int(self.data_frame.iloc[idx, 0])\n",
    "        item = self.data_frame.iloc[idx, 1:].to_numpy()\n",
    "        item = item.reshape((28, 28, 1))\n",
    "        if self.transform:\n",
    "          item = self.transform(item)\n",
    "        sample = {'item': item, \"label\": label}\n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "\n",
    "\n",
    "%time dataSet = ImageSet(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 348 Âµs, sys: 2.71 ms, total: 3.06 ms\n",
      "Wall time: 6.82 ms\n"
     ]
    }
   ],
   "source": [
    "%time dataLoader = DataLoader(dataSet, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing the CNN\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1 , 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 6, 3)\n",
    "        self.conv3 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 48)\n",
    "        self.fc3 = nn.Linear(48, 25)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool(F.leaky_relu(self.conv2(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv3(x)))\n",
    "        x = x.reshape(-1, 16 * 5 * 5)\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        x = F.leaky_relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x      \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ConvNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.0001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Loss:  0.2\n",
      "Epoch 1  Loss:  0.0\n",
      "Epoch 2  Loss:  0.0\n",
      "Epoch 3  Loss:  0.0\n",
      "Epoch 4  Loss:  0.0\n",
      "Epoch 5  Loss:  0.0\n",
      "Epoch 6  Loss:  0.0\n",
      "Epoch 7  Loss:  0.0\n",
      "Epoch 8  Loss:  0.0\n",
      "Epoch 9  Loss:  0.0\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dataLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data['item'], data['label']\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    # Calculates average loss over epoch\n",
    "    print(\"Epoch \" + str(epoch), \" Loss: \", round(running_loss/length, 2))\n",
    "\n",
    "torch.save(net.state_dict(), \"checkpoint.pth\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mASL-Translator\u001b[m\u001b[m                  \u001b[34mPostman\u001b[m\u001b[m\r\n",
      "\u001b[30m\u001b[43mAdlm\u001b[m\u001b[m                            \u001b[34mPublic\u001b[m\u001b[m\r\n",
      "\u001b[34mApplications\u001b[m\u001b[m                    \u001b[34mPycharmProjects\u001b[m\u001b[m\r\n",
      "\u001b[34mCreative Cloud Files\u001b[m\u001b[m            \u001b[34mShit\u001b[m\u001b[m\r\n",
      "\u001b[34mDesktop\u001b[m\u001b[m                         \u001b[34mSpring 2019\u001b[m\u001b[m\r\n",
      "\u001b[34mDocuments\u001b[m\u001b[m                       Untitled.ipynb\r\n",
      "\u001b[34mDownloads\u001b[m\u001b[m                       Untitled1.ipynb\r\n",
      "Essay 1 Outline.docx            \u001b[34mVirtual Machines.localized\u001b[m\u001b[m\r\n",
      "\u001b[34mLibrary\u001b[m\u001b[m                         \u001b[34mcode\u001b[m\u001b[m\r\n",
      "\u001b[34mMovies\u001b[m\u001b[m                          \u001b[34mcs61b-software\u001b[m\u001b[m\r\n",
      "\u001b[34mMusic\u001b[m\u001b[m                           \u001b[34mdev\u001b[m\u001b[m\r\n",
      "\u001b[34mNew\u001b[m\u001b[m                             \u001b[34menv\u001b[m\u001b[m\r\n",
      "Normal Processing.ipynb         \u001b[34mopt\u001b[m\u001b[m\r\n",
      "Parallel Processing_Final.ipynb \u001b[34mrepo\u001b[m\u001b[m\r\n",
      "\u001b[34mPictures\u001b[m\u001b[m                        w210-fall19-deepfake.pem\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mASL-Translator\u001b[m\u001b[m                  \u001b[34mPostman\u001b[m\u001b[m\r\n",
      "\u001b[30m\u001b[43mAdlm\u001b[m\u001b[m                            \u001b[34mPublic\u001b[m\u001b[m\r\n",
      "\u001b[34mApplications\u001b[m\u001b[m                    \u001b[34mPycharmProjects\u001b[m\u001b[m\r\n",
      "\u001b[34mCreative Cloud Files\u001b[m\u001b[m            \u001b[34mShit\u001b[m\u001b[m\r\n",
      "\u001b[34mDesktop\u001b[m\u001b[m                         \u001b[34mSpring 2019\u001b[m\u001b[m\r\n",
      "\u001b[34mDocuments\u001b[m\u001b[m                       Untitled.ipynb\r\n",
      "\u001b[34mDownloads\u001b[m\u001b[m                       Untitled1.ipynb\r\n",
      "Essay 1 Outline.docx            \u001b[34mVirtual Machines.localized\u001b[m\u001b[m\r\n",
      "\u001b[34mLibrary\u001b[m\u001b[m                         \u001b[34mcode\u001b[m\u001b[m\r\n",
      "\u001b[34mMovies\u001b[m\u001b[m                          \u001b[34mcs61b-software\u001b[m\u001b[m\r\n",
      "\u001b[34mMusic\u001b[m\u001b[m                           \u001b[34mdev\u001b[m\u001b[m\r\n",
      "\u001b[34mNew\u001b[m\u001b[m                             \u001b[34menv\u001b[m\u001b[m\r\n",
      "Normal Processing.ipynb         \u001b[34mopt\u001b[m\u001b[m\r\n",
      "Parallel Processing_Final.ipynb \u001b[34mrepo\u001b[m\u001b[m\r\n",
      "\u001b[34mPictures\u001b[m\u001b[m                        w210-fall19-deepfake.pem\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"asl-dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/arth/Desktop'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 6, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=48, bias=True)\n",
       "  (fc3): Linear(in_features=48, out_features=25, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model weights\n",
    "model_url = torch.load(\"checkpoint.pth\")\n",
    "batch_size = 1    # just a random number\n",
    "\n",
    "# Initialize model with the pretrained weights\n",
    "net = ConvNet().float().eval()\n",
    "net.load_state_dict(model_url)\n",
    "\n",
    "# set the model to inference mode\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"signlanguage.onnx\"\n",
    "dummy = torch.randn(batch_size, 28, 28, batch_size)\n",
    "torch.onnx.export(net, dummy, fname, input_names=['input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"signlanguage.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-79456dc99ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mletter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_to_letter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthickness\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "def center_crop(frame):\n",
    "    h, w, _ = frame.shape\n",
    "    start = abs(h - w) // 2\n",
    "    if h > w:\n",
    "        return frame[start: start + w]\n",
    "    return frame[:, start: start + h]\n",
    "\n",
    "# constants\n",
    "index_to_letter = list('ABCDEFGHIKLMNOPQRSTUVWXY')\n",
    "mean = 0.485 * 255.\n",
    "std = 0.229 * 255.\n",
    "\n",
    "# create runnable session with exported model\n",
    "ort_session = ort.InferenceSession(\"signlanguage.onnx\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # preprocess data\n",
    "    frame = center_crop(frame)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "    x = cv2.resize(frame, (28, 28))\n",
    "    x = (x - mean) / std\n",
    "\n",
    "    x = x.reshape(1, 1, 28, 28).astype(np.float32)\n",
    "    x = x.transpose(0, 3, 2, 1)\n",
    "    y = ort_session.run(None, {'input': x})[0]\n",
    "\n",
    "    index = np.argmax(y, axis=1)\n",
    "    letter = index_to_letter[int(index)]\n",
    "\n",
    "    cv2.putText(frame, letter, (100, 100), cv2.FONT_HERSHEY_SIMPLEX, 2.0, (0, 255, 0), thickness=2)\n",
    "    cv2.imshow(\"Sign Language Translator\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:signum]",
   "language": "python",
   "name": "conda-env-signum-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
